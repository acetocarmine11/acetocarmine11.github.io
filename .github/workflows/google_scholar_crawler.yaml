name: Get Citation Data

on: 
  schedule:
    - cron: '0 8 * * *'
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 30  # è®¾ç½®æ•´ä¸ªjobçš„è¶…æ—¶æ—¶é—´
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # è·å–å®Œæ•´çš„Gitå†å²
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: System Information
      run: |
        echo "ğŸ–¥ï¸  ç³»ç»Ÿä¿¡æ¯:"
        echo "  - æ“ä½œç³»ç»Ÿ: $(uname -a)"
        echo "  - Pythonç‰ˆæœ¬: $(python --version)"
        echo "  - æ—¶é—´: $(date)"
        echo "  - ç½‘ç»œæ¥å£:"
        ip addr show | grep inet || true
    
    - name: Network Diagnostics
      run: |
        echo "ğŸŒ ç½‘ç»œè¯Šæ–­:"
        echo "  - æµ‹è¯•DNSè§£æ..."
        nslookup scholar.google.com || echo "DNSè§£æå¤±è´¥"
        echo "  - æµ‹è¯•è¿é€šæ€§..."
        ping -c 3 8.8.8.8 || echo "ç½‘ç»œè¿é€šæ€§æµ‹è¯•å¤±è´¥"
        echo "  - æµ‹è¯•HTTPSè¿æ¥..."
        curl -I https://scholar.google.com --connect-timeout 10 || echo "HTTPSè¿æ¥æµ‹è¯•å¤±è´¥"
    
    - name: Install dependencies
      run: |
        echo "ğŸ“¦ å®‰è£…Pythonä¾èµ–..."
        cd ./google_scholar_crawler
        python -m pip install --upgrade pip
        echo "ğŸ“‹ requirements.txtå†…å®¹:"
        cat requirements.txt
        echo "ğŸ”§ å¼€å§‹å®‰è£…ä¾èµ–..."
        pip install -r requirements.txt --verbose
        echo "âœ… ä¾èµ–å®‰è£…å®Œæˆ"
    
    - name: Verify Installation
      run: |
        echo "ğŸ” éªŒè¯å®‰è£…..."
        cd ./google_scholar_crawler
        python -c "import scholarly; print('âœ… scholarlyåº“å¯¼å…¥æˆåŠŸ')"
        python -c "import fake_useragent; print('âœ… fake_useragentåº“å¯¼å…¥æˆåŠŸ')"
        python -c "import jsonpickle; print('âœ… jsonpickleåº“å¯¼å…¥æˆåŠŸ')"
    
    - name: Run Google Scholar crawler
      timeout-minutes: 20  # è®¾ç½®çˆ¬è™«è¿è¡Œçš„è¶…æ—¶æ—¶é—´
      run: |
        echo "ğŸš€ å¼€å§‹è¿è¡ŒGoogle Scholarçˆ¬è™«..."
        cd ./google_scholar_crawler
        
        # è®¾ç½®è°ƒè¯•æ¨¡å¼
        export PYTHONUNBUFFERED=1
        export PYTHONIOENCODING=utf-8
        
        # è¿è¡Œçˆ¬è™«å¹¶æ•è·è¾“å‡º
        python main.py 2>&1 | tee crawler_output.log
        
        echo "ğŸ“Š çˆ¬è™«è¿è¡Œå®Œæˆï¼Œæ£€æŸ¥è¾“å‡ºæ–‡ä»¶..."
        if [ -f "results/gs_data.json" ]; then
          echo "âœ… gs_data.json æ–‡ä»¶å·²ç”Ÿæˆ"
          echo "ğŸ“„ æ–‡ä»¶å¤§å°: $(wc -c < results/gs_data.json) bytes"
        else
          echo "âŒ gs_data.json æ–‡ä»¶æœªç”Ÿæˆ"
          exit 1
        fi
        
        if [ -f "results/gs_data_shieldsio.json" ]; then
          echo "âœ… gs_data_shieldsio.json æ–‡ä»¶å·²ç”Ÿæˆ"
          cat results/gs_data_shieldsio.json
        else
          echo "âŒ gs_data_shieldsio.json æ–‡ä»¶æœªç”Ÿæˆ"
        fi
      env: 
        GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
    
    - name: Upload crawler logs (on failure)
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: crawler-logs
        path: |
          google_scholar_crawler/crawler_output.log
          google_scholar_crawler/results/
    
    - name: Commit and push results
      run: |
        echo "ğŸ“¤ å‡†å¤‡æäº¤å’Œæ¨é€ç»“æœ..."
        cd ./google_scholar_crawler/results
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ç”Ÿæˆ
        if [ ! -f "gs_data.json" ]; then
          echo "âŒ æ²¡æœ‰æ•°æ®æ–‡ä»¶ç”Ÿæˆï¼Œé€€å‡º..."
          exit 1
        fi
        
        echo "ğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨:"
        ls -la
        
        # é…ç½®Git
        git config --global user.name "${GITHUB_ACTOR}"
        git config --global user.email "${GITHUB_ACTOR}@users.noreply.github.com"
        
        # åˆå§‹åŒ–Gitä»“åº“å¹¶æ·»åŠ æ–‡ä»¶
        git init
        git add *.json
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å˜æ›´
        if git diff --staged --quiet; then
          echo "ğŸ“ æ²¡æœ‰å˜æ›´éœ€è¦æäº¤"
          exit 0
        fi
        
        echo "ğŸ“¤ æäº¤å˜æ›´å¹¶æ¨é€åˆ°google-scholar-statsåˆ†æ”¯..."
        # æäº¤å¹¶æ¨é€åˆ°google-scholar-statsåˆ†æ”¯
        git commit -m "Updated Citation Data - $(date '+%Y-%m-%d %H:%M:%S')"
        git remote add origin "https://${GITHUB_ACTOR}:${{ secrets.GITHUB_TOKEN }}@github.com/${GITHUB_REPOSITORY}.git"
        git push origin HEAD:google-scholar-stats --force
        echo "âœ… æ•°æ®å·²æˆåŠŸæ¨é€åˆ°google-scholar-statsåˆ†æ”¯"